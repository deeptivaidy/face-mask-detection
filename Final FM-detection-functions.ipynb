{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the face mask detector.\n",
    "\n",
    "The following code utilizes Faster R-CNN in order to perform object detection and detec face masks on people in a picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store image's directory into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve image imformation\n",
    "import os\n",
    "image_directories = []\n",
    "for dirname, _, filenames in os.walk('archive/images/'):\n",
    "    for filename in filenames:\n",
    "        image_directories.append(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataframe based on image's found in XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dic = {\"image\": [],\"Dimensions\": []}\n",
    "for i in range(1,116):\n",
    "\tdic[f'Object {i}']=[]\n",
    "print(\"Generating data in CSV format....\")\n",
    "\n",
    "img_elem = []\n",
    "img_count = []\n",
    "\n",
    "for file in os.listdir(\"archive/annotations\"):\n",
    "    row = []\n",
    "    xml = et.parse(\"archive/annotations/\"+file) \n",
    "    root = xml.getroot()\n",
    "    \n",
    "    img = root[1].text\n",
    "    row.append(img)\n",
    "    \n",
    "    num_img = int(img[12:-4])\n",
    "    img_count.append(num_img)\n",
    "    \n",
    "    h,w = root[2][0].text,root[2][1].text\n",
    "    count = 0\n",
    "    row.append([h,w])\n",
    "    temp_img = []\n",
    "    for i in range(4,len(root)):\n",
    "        temp = []\n",
    "        if root[i][0].text != \"mask_weared_incorrect\":\n",
    "            \n",
    "            temp.append(root[i][0].text)\n",
    "            count +=1\n",
    "    #         print(root[i][0].text)\n",
    "            temp_img.append(root[i][0].text) \n",
    "            for point in root[i][5]:\n",
    "                temp.append(point.text)\n",
    "            row.append(temp)\n",
    "#     img_elem.append(temp_img)\n",
    "    img_elem.append(count)\n",
    "    \n",
    "    for i in range(len(row),119):\n",
    "        row.append(0)\n",
    "    for i,each in enumerate(dic):\n",
    "        dic[each].append(row[i])\n",
    "#Main data\n",
    "df = pd.DataFrame(dic)\n",
    "#bounding box information for understanding data\n",
    "df2 = pd.DataFrame(img_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "\n",
    "#### Remove pictures with \"mask_weared_incorrect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes any pictures that formerly only had the \"mask_weared_incorrect\" label\n",
    "for i in df.index.values:\n",
    "    if isinstance(df[\"Object 1\"][i], int):\n",
    "        df = df.drop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes any images containing 40 or more bounding boxes\n",
    "seriesObj = df2.apply(lambda x: True if x[0] < 40 else False, axis=1)\n",
    "# print(type(seriesObj))\n",
    "# print(len(df))\n",
    "\n",
    "index = seriesObj[seriesObj == False].index.values\n",
    "# print(list(index))\n",
    "df = df.drop(index=list(index))\n",
    "df2 = df2.drop(index=list(index))\n",
    "# print(len(df))\n",
    "\n",
    "#Removes extra columns\n",
    "for i in range (40, 116):\n",
    "    col_name = \"Object \"+ str(i)\n",
    "    df.pop(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat DF to Bounding Box entry DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_dict = {\"Image\": [], \"ClassName\": [], \"XMin\": [], \"XMax\": [], \"YMin\": [], \"YMax\": []}\n",
    "\n",
    "for row in df.index.values:\n",
    "    j = 0\n",
    "    for col in df.columns:\n",
    "        if (j < 2):\n",
    "            j += 1\n",
    "            continue\n",
    "        if (df[col][row] == 0):\n",
    "            break\n",
    "        x, y = df[\"Dimensions\"][row]\n",
    "        x = int(x)\n",
    "        y = int(y)\n",
    "        bb_dict[\"Image\"].append(df[\"image\"][row])\n",
    "        bb_dict[\"ClassName\"].append(df[col][row][0])\n",
    "        x1 = int(df[col][row][1])\n",
    "        x2 = int(df[col][row][3])\n",
    "        y1 = int(df[col][row][2])\n",
    "        y2 = int(df[col][row][4])\n",
    "        \n",
    "        \n",
    "        bb_dict[\"XMin\"].append(x1 / x)\n",
    "        bb_dict[\"XMax\"].append(x2 / x)\n",
    "        bb_dict[\"YMin\"].append(y1 / y)\n",
    "        bb_dict[\"YMax\"].append(y2 / y)\n",
    "\n",
    "bb_df = pd.DataFrame(bb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_df.groupby(bb_df.ClassName == 'with_mask').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_df.to_csv('annotate.txt', header=None, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train, test = train_test_split(bb_df, test_size=0.2, shuffle=True)\n",
    "# train, test = train_test_split(df, test_size=0.2)\n",
    "train_df = bb_df.sample(frac=0.8,random_state=200) #random state is a seed value\n",
    "test_df = bb_df.drop(train_df.index)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio as io\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "iou_img_path = 'archive/images/maksssksksss266.png'\n",
    "img = io.imread(iou_img_path)\n",
    "xmin = int(0.245847 * img.shape[1])\n",
    "xmax = int(0.598007 * img.shape[1])\n",
    "ymin = int(0.512500 * img.shape[0])\n",
    "ymax = int(0.825000 * img.shape[0])\n",
    "cv2.rectangle(img, (xmin,ymin), (xmax,ymax), 45, 2)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img, 'dataset label', (xmin,ymin-10), font, 0.5, (0,255,0), 1)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bbox(img_id):\n",
    "#     img_url = images_boxable.loc[images_boxable[\"ImageID\"]==img_id]['OriginalURL'].values[0]\n",
    "#     img = io.imread(img_url)\n",
    "#     height, width, channel = img.shape\n",
    "#     print(f\"Image: {img.shape}\")\n",
    "#     bboxs = annotations_bbox[annotations_bbox['ImageID']==img_id]\n",
    "\n",
    "    k = 0\n",
    "\n",
    "    for idx in bb_dict: \n",
    "        if k > 10: \n",
    "            break\n",
    "        k += 1\n",
    "        xmin = bb_dict['XMin'][idx]\n",
    "        xmax = bb_dict['XMax'][idx]\n",
    "        ymin = bb_dict['YMin'][idx]\n",
    "        ymax = bb_dict['YMax'][idx]\n",
    "        img_path = bb_dict['Image'][idx]\n",
    "        img = cv2.imread('archive/images/' + str(img_path))\n",
    "        \n",
    "        x = img.shape[0]\n",
    "        y = img.shape[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bbox(img_id):\n",
    "#     img_url = images_boxable.loc[images_boxable[\"ImageID\"]==img_id]['OriginalURL'].values[0]\n",
    "#     img = io.imread(img_url)\n",
    "#     height, width, channel = img.shape\n",
    "#     print(f\"Image: {img.shape}\")\n",
    "#     bboxs = annotations_bbox[annotations_bbox['ImageID']==img_id]\n",
    "\n",
    "    k = 0\n",
    "\n",
    "    for idx in bb_dict: \n",
    "        if k > 10: \n",
    "            break\n",
    "        k += 1\n",
    "        xmin = bb_dict['XMin'][idx]\n",
    "        xmax = bb_dict['XMax'][idx]\n",
    "        ymin = bb_dict['YMin'][idx]\n",
    "        ymax = bb_dict['YMax'][idx]\n",
    "        img_path = bb_dict['Image'][idx]\n",
    "        img = cv2.imread('archive/images/' + str(img_path))\n",
    "        \n",
    "        x = img.shape[0]\n",
    "        y = img.shape[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_x = 0\n",
    "max_y = 0\n",
    "lengths = []\n",
    "widths = []\n",
    "for index in df.index.values:\n",
    "    max_x = int(df[\"Dimensions\"][index][0]) if int(df[\"Dimensions\"][index][0]) > max_x else max_x\n",
    "    lengths.append(int(df[\"Dimensions\"][index][0]))\n",
    "    max_y = int(df[\"Dimensions\"][index][1]) if int(df[\"Dimensions\"][index][1]) > max_y else max_y\n",
    "    widths.append(int(df[\"Dimensions\"][index][1]))\n",
    "print(max_x, max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.image as mplib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#This includes ideal padding for images, however we need to find a way to adjust each bounding box accordingly \n",
    "for i in df.index.values:\n",
    "    img = mplib.imread(image_directories[i])\n",
    "#     print(\"before: \", img)\n",
    "    Y, X = df[\"Dimensions\"][i]\n",
    "#     print(max_x-int(X), max_y-int(Y))\n",
    "    new_img = img\n",
    "    if (max_y-int(Y)) <  (max_x-int(X)):\n",
    "        new_x = max_y - int(Y)+int(X)\n",
    "        new_img = cv2.resize(img, (new_x, max_y))\n",
    "#         print(new_x)\n",
    "        new_img = cv2.copyMakeBorder(new_img, 0, 0, 0, max_x - new_x, cv2.BORDER_CONSTANT)\n",
    "    elif (max_y-int(Y)) >  (max_x-int(X)):\n",
    "        new_y = max_x - int(X)+int(Y)\n",
    "        new_img = cv2.resize(img, (max_x, new_y))\n",
    "        new_img = cv2.copyMakeBorder(new_img, 0, max_y-new_y, 0, 0, cv2.BORDER_CONSTANT)\n",
    "#     print(max_x-(max_y - int(X)+int(Y)))\n",
    "#     if max_x-(max_y - int(X)+int(Y)) > 0:\n",
    "#         new_img = cv2.copyMakeBorder(img, 0, 0, 0,max_x-(max_y - int(X)+int(Y)), cv2.BORDER_CONSTANT)\n",
    "#     else:\n",
    "#         new_img = cv2.copyMakeBorder(img, 0, max_y - max_x - , 0, max_x - max_y-int(X), cv2.BORDER_CONSTANT)\n",
    "#     plt.imshow(mpl_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_img.shape)\n",
    "plt.imshow(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "img_arr = []\n",
    "\n",
    "for i in df.index.values:\n",
    "#     print(image_directories[i])\n",
    "    img = mplib.imread(os.path.join(\"archive/images/\", df[\"image\"][i]))\n",
    "    fig,ax = plt.subplots(1)\n",
    "\n",
    "    # Display the image\n",
    "    \n",
    "    \n",
    "#     print(\"before: \", img)\n",
    "    X, Y = df[\"Dimensions\"][i]\n",
    "    img = cv2.copyMakeBorder(img, 0, max_y - int(Y), 0, max_x-int(X), cv2.BORDER_CONSTANT)\n",
    "    print(i)\n",
    "    ax.imshow(img)\n",
    "    first_box = df[\"Object 1\"][i]\n",
    "    if isinstance(first_box, list) :\n",
    "#         print(first_box[1])\n",
    "        x_min = first_box[1]\n",
    "        y_min = first_box[2]\n",
    "        x_max = first_box[3]\n",
    "        y_max = first_box[4]\n",
    "        rect = patches.Rectangle((int(x_min),int(y_min)),\n",
    "                                 int(x_max)-int(x_min),\n",
    "                                 int(y_max)-int(y_min),\n",
    "                                 linewidth=1,edgecolor='r',facecolor='none')\n",
    "\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "        img_arr.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "variances = np.array(v)\n",
    "print(v)\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.plot(range(1, 40, 3), v, marker='o')\n",
    "ax.set_xlabel(\"Principle Components\")\n",
    "ax.set_ylabel(\"Variance\")\n",
    "ax.set_title(\"Variance for Various Principle Component Values in PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_img = np.reshape(img_arr[3], (img.shape[0], img.shape[1]*img.shape[2]))\n",
    "        \n",
    "pca = PCA(18).fit(reshaped_img) \n",
    "img_transformed = pca.transform(reshaped_img)\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "temp = pca.inverse_transform(img_transformed) \n",
    "print(temp.shape)\n",
    "temp = np.reshape(temp, (600,600 ,4)) \n",
    "print(temp.shape) \n",
    "plt.imshow(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "import random\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import pickle\n",
    "import math\n",
    "import cv2\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.objectives import categorical_crossentropy\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.utils import generic_utils\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras import initializers, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_output_length(width, height):\n",
    "    return width//16, height//16    \n",
    "\n",
    "def nn_base(tensor=None, trainable=False):\n",
    "\n",
    "    input_shape = (None, None, 3)\n",
    "\n",
    "    if not K.is_keras_tensor(input_tensor):\n",
    "        img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "    else:\n",
    "        img_input = tensor\n",
    "\n",
    "    r = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    r = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(r)\n",
    "    r = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(r)\n",
    "    r = Confdov2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(r)\n",
    "    r = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(r)\n",
    "    r = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(r)\n",
    "    r = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(r)\n",
    "    r = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(r)\n",
    "    r = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(r)\n",
    "    r = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(r)\n",
    "    r = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(r)\n",
    "    r = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(r)\n",
    "    r = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(r)\n",
    "    r = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(r)\n",
    "    r = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(r)\n",
    "    r = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(r)\n",
    "    r = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(lyrs, i_rois, nums, nb = 4):\n",
    "    pool = RoiPoolingConv(7, nums)([lyrs, i_rois])\n",
    "    k = TimeDistributed(Flatten(name='flatten'))(pool)\n",
    "    l = TimeDistributed(Dense(4096, activation='relu', name='fc1'))(l)\n",
    "    l = TimeDistributed(Dropout(0.5))(l)\n",
    "    l = TimeDistributed(Dense(4096, activation='relu', name='fc2'))(l)\n",
    "    l = TimeDistributed(Dropout(0.5))(l)\n",
    "    l_cl = TimeDistributed(Dense(nb_classes, activation='softmax', kernel_initializer='zero'), name='dense_class_{}'.format(nb))(l)\n",
    "    l_r = TimeDistributed(Dense(4 * (nb_classes-1), activation='linear', kernel_initializer='zero'), name='dense_regress_{}'.format(nb))(l)\n",
    "    return [l_cl, lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting RPN Layer to ROI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpn_to_roi(rpn_layer, regr_layer, C, dim_ordering, use_regr=True, max_boxes=300,overlap_thresh=0.9):\n",
    "\n",
    "    regr_layer = regr_layer / C.std_scaling\n",
    "\n",
    "    rows, cols, _ = rpn_layer.shape\n",
    "    A = np.zeros((4, rpn_layer.shape[1], rpn_layer.shape[2], rpn_layer.shape[3]))\n",
    "\n",
    "    for anchor_size in C.anchor_box_scales:\n",
    "        for anchor_ratio in C.anchor_box_ratios:\n",
    "            anchor_x = (anchor_size * anchor_ratio[0])/C.rpn_stride\n",
    "            anchor_y = (anchor_size * anchor_ratio[1])/C.rpn_stride\n",
    "            regr = regr_layer[0, :, :, 4 * curr_layer:4 * curr_layer + 4] \n",
    "            regr = np.transpose(regr, (2, 0, 1)) \n",
    "            X, Y = np.meshgrid(np.arange(cols),np. arange(rows))\n",
    "            A[0, :, :, curr_layer] = X - anchor_x/2 \n",
    "            A[1, :, :, curr_layer] = Y - anchor_y/2 \n",
    "            A[2, :, :, curr_layer] = anchor_x       \n",
    "            A[3, :, :, curr_layer] = anchor_y       \n",
    "            if use_regr:\n",
    "                A[:, :, :, curr_layer] = apply_regr_np(A[:, :, :, curr_layer], regr)\n",
    "            A[2, :, :, curr_layer] = np.maximum(1, A[2, :, :, curr_layer])\n",
    "            A[3, :, :, curr_layer] = np.maximum(1, A[3, :, :, curr_layer])\n",
    "            A[2, :, :, curr_layer] += A[0, :, :, curr_layer]\n",
    "            A[3, :, :, curr_layer] += A[1, :, :, curr_layer]\n",
    "            A[0, :, :, curr_layer] = np.maximum(0, A[0, :, :, curr_layer])\n",
    "            A[1, :, :, curr_layer] = np.maximum(0, A[1, :, :, curr_layer])\n",
    "            A[2, :, :, curr_layer] = np.minimum(cols-1, A[2, :, :, curr_layer])\n",
    "            A[3, :, :, curr_layer] = np.minimum(rows-1, A[3, :, :, curr_layer])\n",
    "            curr_layer += 1\n",
    "    all_boxes = np.reshape(A.transpose((0, 3, 1, 2)), (4, -1)).transpose((1, 0)) \n",
    "    all_probs = rpn_layer.transpose((0, 3, 1, 2)).reshape((-1))                   \n",
    "    x1 = all_boxes[:, 0]\n",
    "    y1 = all_boxes[:, 1]\n",
    "    x2 = all_boxes[:, 2]\n",
    "    y2 = all_boxes[:, 3]\n",
    "    idxs = np.where((x1 - x2 >= 0) | (y1 - y2 >= 0))\n",
    "    all_boxes = np.delete(all_boxes, idxs, 0)\n",
    "    all_probs = np.delete(all_probs, idxs, 0)\n",
    "    result = non_max_suppression_fast(all_boxes, all_probs, overlap_thresh=overlap_thresh, max_boxes=max_boxes)[0]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(first, second):\n",
    "\n",
    "    if first[0] >= first[2] || first[1] >= first[3] || second[0] >= second[2] | second[1] >= second[3]:\n",
    "        return 0\n",
    "\n",
    "    area_i = intersection(first, second)\n",
    "    area_u = union(first, second, area_i)\n",
    "\n",
    "    return float(area_i) / float(area_u + 1e-6)\n",
    "\n",
    "\n",
    "def union(first, second, area_intersection):\n",
    "    area_a = (first[3] - first[1]) * (first[2] - first[0])\n",
    "    area_b = (second[3] - second[1]) * (second[2] - second[0])\n",
    "    \n",
    "    return area_a + area_b - area_intersection\n",
    "\n",
    "\n",
    "def intersection(first, second):\n",
    "    \n",
    "    x = max(first[0], second[0])\n",
    "    y = max(first[1], second[1])\n",
    "    \n",
    "    width = min(first[2], second[2]) - x\n",
    "    height = min(first[3], second[3]) - y\n",
    "    \n",
    "\n",
    "    if height < 0 || width < 0:\n",
    "        return 0\n",
    "    \n",
    "    return width * height"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
